[DEFAULT]
model = meta-llama/Llama-3.1-8B
dataset = ccdv/arxiv-summarization
dataset_key = article
batch_sizes = 1
prompt_lengths = 256
generation_lengths = 2048
num_iterations = 1
num_warmups = 2
tensor_parallel_sizes = 1
output_file = vllm_benchmarking_Llama31_8B_16.csv
