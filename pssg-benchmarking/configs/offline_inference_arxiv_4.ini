[DEFAULT]
model = meta-llama/Llama-3.1-8B
dataset = ccdv/arxiv-summarization
dataset_key = article
batch_sizes = 4
prompt_lengths = 128, 256, 512, 1024, 2048, 4096
generation_lengths = 128, 256, 512, 1024, 2048, 4096
num_iterations = 5
num_warmups = 5
tensor_parallel_sizes = 1
output_file = vllm_benchmarking_Llama31_8B_4.csv
